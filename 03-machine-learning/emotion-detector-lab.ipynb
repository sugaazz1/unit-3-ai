{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab - Emotion Detection with Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Welcome to the Emotion Detection Lab! In this activity, you'll explore the fascinating world of **artificial intelligence** and **machine learning** by building a model that can recognize human emotions from facial expressions.\n",
    "\n",
    "**What you'll learn:**\n",
    "- How machine learning models learn from data\n",
    "- The process of training a neural network\n",
    "- How to evaluate model accuracy\n",
    "- How to test your model with real images\n",
    "\n",
    "**By the end of this lab**, you'll have a working emotion detector that can identify 7 different emotions: Angry, Disgust, Fear, Happy, Neutral, Sad, and Surprise!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 0 - Background Research\n",
    "\n",
    "Before diving into the code, let's explore the concepts behind emotion detection and machine learning.\n",
    "\n",
    "To answer the questions, edit the markdown cell and put your answer below the question.\n",
    "\n",
    "**Make sure to save the markdown cell by pressing the ‚úì (check) icon in the top right after answering the questions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 00\n",
    "What is machine learning, and how is it different from traditional programming?\n",
    "- **Answer:** Machine learning is a department in AI that creates algorithms that allows AI to learn and improve on their own, without much of human assistance. It is different from tradtional programming as machine learning learns from it's data and create its own rule.\n",
    "\n",
    "##### Question 01\n",
    "What is a neural network? Why do you think it's called \"neural\"?\n",
    "- **Answer:** A neural network is a type of machine learning inspired by the brain. It's the part that handles complex decision making and patterns to output the perfect result. It's called neural because it's inspired by the brains neural network.\n",
    "\n",
    "\n",
    "##### Question 02\n",
    "Research facial emotion recognition. What are some real-world applications of this technology?\n",
    "- **Answer:** Some real-word applications of this technology are market research, healthcare, human-robot interaction and security.\n",
    "\n",
    "##### Question 03\n",
    "What are some potential ethical concerns with emotion detection AI?\n",
    "- **Answer:** Some potentil ethical concerns with emotion detection AI is that it can include privacy violations, bias and discrimination, manipulation and potention for harm in sensitive contexts like healthcare or employment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 - Setting Up Our Environment\n",
    "\n",
    "First, we need to import the libraries (tools) we'll use to build our emotion detector. Think of these as different toolkits - some for working with numbers, some for creating visualizations, and some specifically designed for machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.0 - Installing Required Libraries\n",
    "\n",
    "Before we can import our libraries, we need to make sure they're installed. Run these commands in your terminal:\n",
    "\n",
    "```bash\n",
    "pip3 install numpy matplotlib tensorflow keras kagglehub scipy\n",
    "```\n",
    "\n",
    "**Note:** This might take a few minutes. Tensorflow is a large library!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 - Importing Libraries\n",
    "\n",
    "Now let's import all the tools we'll need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os                       # For working with files and folders\n",
    "\n",
    "# Basic data manipulation and math\n",
    "import numpy as np              # For working with arrays and numbers\n",
    "\n",
    "# Visualization tools\n",
    "import matplotlib.pyplot as plt # For creating plots and charts\n",
    "\n",
    "# Machine Learning and Neural Networks\n",
    "import tensorflow as tf         # Google's machine learning framework\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from keras import regularizers\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 04\n",
    "Look at the imports above. Which library do you think is responsible for the actual \"machine learning\" part?\n",
    "- **Answer:** I think the library for the actual machine learning part is the tensorflow.\n",
    "\n",
    "##### Question 05\n",
    "We import several tools from keras and tensorflow. Why do you think we need multiple tools instead of just one library?\n",
    "- **Answer:** We need multiple tools instead of just one library because machine learning involves various parts, and to put everything under one library would be alot, hence why we need various imports instead of just one library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 - Downloading the Dataset\n",
    "\n",
    "Now we need to download the emotion detection dataset from Kaggle. This dataset contains thousands of facial images labeled with different emotions.\n",
    "\n",
    "**First, install kagglehub** (if you haven't already):\n",
    "```bash\n",
    "pip3 install kagglehub\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to download the dataset\n",
    "\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version of the FER emotion detection dataset\n",
    "path = kagglehub.dataset_download(\"ananthu017/emotion-detection-fer\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "print(\"\\n‚úÖ Dataset downloaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° **Note:** The download might take a few minutes depending on your internet connection. The dataset is several hundred megabytes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 - Understanding Our Dataset\n",
    "\n",
    "Machine learning models learn from data. Our dataset contains thousands of facial images labeled with different emotions. The model will study these images to learn what patterns (like eyebrow positions, mouth shapes) correspond to each emotion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.0 - Setting Up Data Paths\n",
    "\n",
    "Now we need to tell our program where to find the training and testing images. The dataset was just downloaded in the previous step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up paths to the training and testing data\n",
    "# The 'path' variable was created when we downloaded the dataset\n",
    "train_dir = os.path.join(path, \"train\")\n",
    "test_dir = os.path.join(path, \"test\")\n",
    "\n",
    "# Image size - all images will be resized to 48x48 pixels\n",
    "img_size = 48\n",
    "\n",
    "print(f\"üìÅ Training data location: {train_dir}\")\n",
    "print(f\"üìÅ Testing data location: {test_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 06\n",
    "Why do you think all images need to be the same size (48x48 pixels) for machine learning?\n",
    "- **Answer:** All images need to be the same size for machine learning because it is simplier for the data structure, and it simplifies the data if everything is the same.\n",
    "\n",
    "##### Question 07\n",
    "We have separate folders for \"train\" and \"test\" data. Why do you think we split our data this way instead of using all images for training?\n",
    "- **Answer:** We have separate folders for train and test data because they both folders serves different purpose per their name. Moreover, we don't want to confuse the computer/ the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 - Data Augmentation\n",
    "\n",
    "**Data augmentation** is a technique where we create slightly modified versions of our training images. This helps our model learn better by seeing each face from slightly different perspectives.\n",
    "\n",
    "Think of it like this: if you only studied math problems written in one handwriting style, you might struggle with problems written differently. Data augmentation helps our model generalize better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.optimizers import Adam# Augmentation for training data - we modify these images to create variety\n",
    "train_datagen = ImageDataGenerator(\n",
    "    width_shift_range=0.1,      # Shift image 10% left/right\n",
    "    height_shift_range=0.1,     # Shift image 10% up/down\n",
    "    horizontal_flip=True,       # Randomly flip horizontally\n",
    "    rescale=1./255,             # Scale pixel values to 0-1 range\n",
    "    validation_split=0.2        # Use 20% for validation\n",
    ")\n",
    "\n",
    "# For validation data - we only rescale, no augmentation\n",
    "validation_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Data augmentation configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 08\n",
    "We use `horizontal_flip=True` for data augmentation. Would it make sense to use `vertical_flip` (upside down) for facial emotion detection? Why or why not?\n",
    "- **Answer:** \n",
    "\n",
    "##### Question 09\n",
    "What does `rescale=1./255` do? Why is it helpful to scale pixel values?\n",
    "- **Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 - Loading the Data\n",
    "\n",
    "Now we'll load the actual images from our folders and apply the augmentation we configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training images\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=train_dir,\n",
    "    target_size=(img_size, img_size),  # Resize all images to 48x48\n",
    "    batch_size=64,                      # Process 64 images at a time\n",
    "    color_mode=\"grayscale\",             # Use black & white images (simpler than color)\n",
    "    class_mode=\"categorical\",           # We have multiple emotion categories\n",
    "    subset=\"training\"                   # This is training data\n",
    ")\n",
    "\n",
    "# Load validation images\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    directory=test_dir,\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=64,\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"validation\"\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Data loaded successfully!\")\n",
    "print(f\"üìä Training samples: {train_generator.samples}\")\n",
    "print(f\"üìä Validation samples: {validation_generator.samples}\")\n",
    "print(f\"\\nEmotion classes: {list(train_generator.class_indices.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 10\n",
    "Look at the output above. How many total images are in the training set? How many in the validation set?\n",
    "- **Answer:**\n",
    "\n",
    "##### Question 11\n",
    "We use `color_mode=\"grayscale\"` (black and white) instead of color. What might be an advantage of using grayscale for this task?\n",
    "- **Answer:**\n",
    "\n",
    "##### Question 12\n",
    "Notice that our images are organized into folders with emotion names (like \"happy\", \"sad\", etc.), and each image is labeled with its emotion. This is called **supervised learning** because we're teaching the model using labeled examples. How is this different from **unsupervised learning**, where the model finds patterns without labels? Why do you think we need labeled data for emotion detection?\n",
    "- **Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 - Analyzing the Dataset Distribution\n",
    "\n",
    "Before we build our model, it's important to understand what data we're working with. Let's visualize how many images we have for each emotion.\n",
    "\n",
    "**Why does this matter?** If our dataset has way more images of one emotion than another, the model might become biased!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to visualize the training dataset\n",
    "\n",
    "\n",
    "# Get the count of images for each emotion class\n",
    "emotion_counts = {}\n",
    "for emotion_name, class_index in train_generator.class_indices.items():\n",
    "    count = sum(train_generator.classes == class_index)\n",
    "    emotion_counts[emotion_name] = count\n",
    "\n",
    "# Sort by emotion name for consistent display\n",
    "emotions = sorted(emotion_counts.keys())\n",
    "counts = [emotion_counts[emotion] for emotion in emotions]\n",
    "\n",
    "# Create bar chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(emotions, counts, color='steelblue', edgecolor='black', linewidth=1.2)\n",
    "plt.title('Distribution of Training Images by Emotion', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Emotion', fontsize=12)\n",
    "plt.ylabel('Number of Images', fontsize=12)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add count labels on top of bars\n",
    "for bar, count in zip(bars, counts):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 50,\n",
    "             f'{count:,}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 13\n",
    "Looking at the bar chart above, which emotion has the MOST training images? Which has the LEAST?\n",
    "- **Answer:**\n",
    "\n",
    "##### Question 14\n",
    "If one emotion has significantly more images than another, how might this affect the model's performance? Will it be equally good at recognizing all emotions?\n",
    "- **Answer:**\n",
    "\n",
    "##### Question 15\n",
    "Based on the distribution, which emotion(s) do you predict the model will be BEST at detecting? Which might it struggle with? Explain your reasoning.\n",
    "- **Answer:**\n",
    "\n",
    "##### Question 16\n",
    "If you were building this dataset, why might it be challenging to collect equal numbers of images for each emotion? (Think about which emotions people naturally express more often)\n",
    "- **Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3 - Building the Neural Network\n",
    "\n",
    "Now we'll build our neural network - the \"brain\" of our emotion detector!\n",
    "\n",
    "**What you need to know:**\n",
    "- A neural network is made up of layers that work together to recognize patterns\n",
    "- Each layer looks for different features (edges, shapes, facial features)\n",
    "- The network learns by adjusting itself to make better predictions\n",
    "\n",
    "**The good news:** You don't need to understand every detail of how the network works - that's advanced computer science! The important part is understanding what the network does overall and how to train it.\n",
    "\n",
    "Think of it like driving a car - you don't need to know how the engine works to drive successfully!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.0 - Creating the Model\n",
    "\n",
    "The code below creates our neural network. It's pre-built for you! \n",
    "\n",
    "**What's happening (simplified):**\n",
    "- The network has multiple layers that process the image\n",
    "- Early layers detect simple patterns (like edges)\n",
    "- Later layers detect complex patterns (like facial features)\n",
    "- The final layer makes a decision about which emotion it sees\n",
    "\n",
    "Just run the cell - the details aren't the focus of this activity!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to create the neural network model\n",
    "\n",
    "# Create a Sequential model (layers stacked one after another)\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# Layer 1-2: Look for basic patterns (edges, lines)\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', \n",
    "                 input_shape=(48, 48, 1)))\n",
    "model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Layer 3: Look for shapes and curves\n",
    "model.add(Conv2D(128, (5,5), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Layer 4-5: Look for complex facial features\n",
    "model.add(Conv2D(512, (3,3), padding='same', activation='relu', \n",
    "                 kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(512, (3,3), padding='same', activation='relu', \n",
    "                 kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Decision layers: Combine patterns and make predictions\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Output layer: Gives probability for each of the 7 emotions\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "print(\"‚úÖ Neural network created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 17\n",
    "The neural network was created for you. Why do you think we have 7 outputs in the final layer?\n",
    "- **Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 - Configuring the Model\n",
    "\n",
    "Before training, we need to configure how the model learns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the learning process\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Model configured and ready to train!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 - Model Summary (Optional)\n",
    "\n",
    "If you're curious about the model's structure, you can view a summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° **Note:** The model has millions of parameters (numbers) that need to be learned during training. That's why we need lots of training data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4 - Training the Model\n",
    "\n",
    "This is where the magic happens! The model will look at thousands of facial images and gradually learn to recognize patterns associated with each emotion.\n",
    "\n",
    "**What happens during training:**\n",
    "1. Model looks at a batch of images and makes predictions\n",
    "2. Compares predictions to correct answers\n",
    "3. Adjusts its internal parameters to be more accurate\n",
    "4. Repeats for many epochs (complete passes through the data)\n",
    "\n",
    "**‚ö†Ô∏è Important:** Training will take a while (potentially 30+ minutes depending on your computer). You can reduce the number of epochs if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.0 - Setting Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "epochs = 60        # Number of complete passes through the training data\n",
    "batch_size = 64    # Number of images processed at once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 18\n",
    "What is an \"epoch\"? Why do we need multiple epochs instead of just one pass through the data?\n",
    "- **Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 - Training the Model\n",
    "\n",
    "Now let's train! Watch the accuracy increase over time. The model is learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "print(\"üöÄ Starting training...\\n\")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    verbose=1  # Show progress\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 19\n",
    "Look at the training output above. Did the accuracy increase from the first epoch to the last epoch? By approximately how much?\n",
    "- **Answer:**\n",
    "\n",
    "##### Question 20\n",
    "You should see two accuracy values each epoch: training accuracy and validation accuracy. Why is the validation accuracy usually lower than training accuracy?\n",
    "- **Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 - Visualizing Training Progress\n",
    "\n",
    "Let's create graphs to see how our model improved during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two subplots: one for accuracy, one for loss\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot accuracy\n",
    "ax1.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "ax1.set_title('Model Accuracy Over Time')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Plot loss\n",
    "ax2.plot(history.history['loss'], label='Training Loss')\n",
    "ax2.plot(history.history['val_loss'], label='Validation Loss')\n",
    "ax2.set_title('Model Loss Over Time')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Training history visualized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 21\n",
    "Look at the accuracy graph. Does the accuracy reach a plateau (flatten out), or is it still improving at the end?\n",
    "- **Answer:**\n",
    "\n",
    "##### Question 22\n",
    "The \"loss\" represents how wrong the model's predictions are (lower is better). Describe the shape of the loss curve. What does it tell you about the model's learning?\n",
    "- **Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5 - Evaluating the Model\n",
    "\n",
    "Now that training is complete, let's see how well our model performs on data it has never seen before!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.0 - Testing on Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on training data (data the model has seen)\n",
    "train_loss, train_acc = model.evaluate(train_generator)\n",
    "\n",
    "# Evaluate on test data (data the model has NOT seen)\n",
    "test_loss, test_acc = model.evaluate(validation_generator)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üìä FINAL RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Training Accuracy:   {train_acc*100:.2f}%\")\n",
    "print(f\"Validation Accuracy: {test_acc*100:.2f}%\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Calculate overfitting\n",
    "overfitting = train_acc - test_acc\n",
    "if overfitting > 0.1:\n",
    "    print(f\"\\n‚ö†Ô∏è  Warning: Model may be overfitting (difference: {overfitting*100:.2f}%)\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Model generalization looks good! (difference: {overfitting*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 23\n",
    "What was your final validation accuracy? How does it compare to random guessing (which would be about 14.3% for 7 emotions)?\n",
    "- **Answer:**\n",
    "\n",
    "##### Question 24\n",
    "Is there a big difference between training accuracy and validation accuracy? What might this indicate about the model?\n",
    "- **Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 - Saving the Model\n",
    "\n",
    "Let's save our trained model so we don't have to retrain it every time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model weights\n",
    "model.save_weights('emotion_detector.weights.h5')\n",
    "print(\"‚úÖ Model weights saved to 'emotion_detector.weights.h5'\")\n",
    "\n",
    "# To load the model later, you would use:\n",
    "# model.load_weights('emotion_detector.weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a file called `.gitignore` and put the name of the model weights file (`emotion_detector.weights.h5`) to make sure it is not uploaded to GitHub. \n",
    "\n",
    "This file is too large to be sent to GitHub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 6 - Testing With Your Own Images!\n",
    "\n",
    "This is the fun part - let's test our emotion detector with real images! You can use:\n",
    "- Photos from the test dataset\n",
    "- Your own photos\n",
    "- Photos you find online\n",
    "\n",
    "**Image requirements:**\n",
    "- Should clearly show a face\n",
    "- Face should be well-lit\n",
    "- Works best with frontal faces (not profile views)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.0 - Setting Up Emotion Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary mapping numbers to emotion names\n",
    "label_dict = {\n",
    "    0: 'Angry',\n",
    "    1: 'Disgust',\n",
    "    2: 'Fear',\n",
    "    3: 'Happy',\n",
    "    4: 'Neutral',\n",
    "    5: 'Sad',\n",
    "    6: 'Surprise'\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Emotion labels configured\")\n",
    "print(\"\\nEmotions our model can detect:\")\n",
    "for key, value in label_dict.items():\n",
    "    print(f\"   {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 - Loading and Processing an Image\n",
    "\n",
    "**TODO:** Update the image path below to test with your own image!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Change this to your image path\n",
    "image_path = \"path/to/your/image.jpg\"\n",
    "\n",
    "# Load and preprocess the image\n",
    "img = image.load_img(image_path, color_mode=\"grayscale\", target_size=(img_size, img_size))\n",
    "\n",
    "# Display the original image\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title(\"Test Image\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Image loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 - Making a Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert image to array and preprocess\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "img_array = img_array.reshape(1, 48, 48, 1)    # Reshape to match model input\n",
    "img_array = img_array / 255.0                   # Normalize pixel values\n",
    "\n",
    "# Make prediction\n",
    "result = model.predict(img_array)\n",
    "result_list = list(result[0])\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üîÆ PREDICTION RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nProbability for each emotion:\")\n",
    "for i, prob in enumerate(result_list):\n",
    "    print(f\"   {label_dict[i]:<10} : {prob*100:5.2f}%\")\n",
    "\n",
    "# Find the emotion with highest probability\n",
    "img_index = result_list.index(max(result_list))\n",
    "predicted_emotion = label_dict[img_index]\n",
    "confidence = max(result_list) * 100\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"üéØ PREDICTED EMOTION: {predicted_emotion}\")\n",
    "print(f\"üí™ Confidence: {confidence:.2f}%\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 25\n",
    "Test your model with at least 3 different images. Record the results:\n",
    "- Image 1: Actual emotion: ______ | Predicted emotion: ______ | Confidence: ______\n",
    "- Image 2: Actual emotion: ______ | Predicted emotion: ______ | Confidence: ______\n",
    "- Image 3: Actual emotion: ______ | Predicted emotion: ______ | Confidence: ______\n",
    "\n",
    "##### Question 26\n",
    "How accurate was your model on these test images? Were there any surprising results?\n",
    "- **Answer:**\n",
    "\n",
    "##### Question 27\n",
    "Look at the probability percentages for all emotions. Even when the model is confident, do other emotions sometimes have non-zero probabilities? What might this tell you about how the model works?\n",
    "- **Answer:**\n",
    "\n",
    "##### Question 27b (Connecting back to Part 2.3)\n",
    "Look back at your answer to Question 15 about the data distribution. Did the model perform better on emotions that had more training images? Compare your prediction to the actual results.\n",
    "- **Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3 - Visualizing Predictions (OPTIONAL)\n",
    "\n",
    "Let's create a bar chart showing the probabilities for all emotions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bar chart of predictions\n",
    "emotions = list(label_dict.values())\n",
    "probabilities = [p * 100 for p in result_list]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(emotions, probabilities, color='skyblue')\n",
    "\n",
    "# Highlight the predicted emotion\n",
    "bars[img_index].set_color('green')\n",
    "\n",
    "plt.title('Emotion Detection Probabilities', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Emotion', fontsize=12)\n",
    "plt.ylabel('Probability (%)', fontsize=12)\n",
    "plt.ylim(0, 100)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add percentage labels on bars\n",
    "for i, (bar, prob) in enumerate(zip(bars, probabilities)):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "             f'{prob:.1f}%', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 7 - Reflection and Analysis\n",
    "\n",
    "Now that you've built, trained, and tested your emotion detector, let's reflect on what you learned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 28\n",
    "Describe the complete machine learning process you went through in this lab (from data loading to making predictions).\n",
    "- **Answer:**\n",
    "\n",
    "##### Question 29\n",
    "What factors do you think might affect the accuracy of emotion detection? (Think about image quality, lighting, facial expressions, etc.)\n",
    "- **Answer:**\n",
    "\n",
    "##### Question 30\n",
    "If you wanted to improve this model's performance, what are some things you could try? (Consider: more data, different architecture, more training time, etc.)\n",
    "- **Answer:**\n",
    "\n",
    "##### Question 31\n",
    "This model was trained on a specific dataset. Do you think it would work equally well on people of all ages, ethnicities, and cultures? Why or why not?\n",
    "- **Answer:**\n",
    "\n",
    "##### Question 32\n",
    "Think about the ethical implications: Should emotion detection AI be used in schools, workplaces, or public spaces? What are the potential benefits and concerns?\n",
    "- **Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Congratulations! üéâ You've successfully:\n",
    "- Built a convolutional neural network from scratch\n",
    "- Trained a machine learning model on thousands of images\n",
    "- Evaluated model performance\n",
    "- Made predictions on real images\n",
    "- Explored the ethical implications of AI\n",
    "\n",
    "You now have hands-on experience with one of the most exciting areas of artificial intelligence!\n",
    "\n",
    "**Key Takeaways:**\n",
    "- Machine learning models learn patterns from data\n",
    "- Neural networks consist of layers that detect increasingly complex patterns\n",
    "- Training requires large datasets and computational power\n",
    "- Model evaluation is crucial to ensure generalization\n",
    "- AI technology raises important ethical questions\n",
    "\n",
    "**Remember:** This is just the beginning of your AI journey. Keep exploring, experimenting, and learning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Resources for Further Learning\n",
    "\n",
    "- **TensorFlow Tutorials**: https://www.tensorflow.org/tutorials\n",
    "- **Keras Documentation**: https://keras.io/\n",
    "- **Deep Learning Specialization**: https://www.coursera.org/specializations/deep-learning\n",
    "- **Papers with Code**: https://paperswithcode.com/\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
